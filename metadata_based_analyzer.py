import sqlite3
import re
from datetime import datetime, timedelta
from collections import Counter
import json

class MetadataBasedAnalyzer:
    def __init__(self):
        self.DBName = 'google_news.db'
        self.db = sqlite3.connect(self.DBName, check_same_thread=False)
        self.db.row_factory = sqlite3.Row
        
        # ê°ì • ë¶„ì„ í‚¤ì›Œë“œ (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)
        self.sentiment_keywords = {
            'positive': [
                'ìƒìŠ¹', 'ê¸‰ë“±', 'ëŒíŒŒ', 'ì‹ ê¸°ë¡', 'ì„±ì¥', 'í™•ëŒ€', 'ì¦ê°€', 'ê°œì„ ', 'í˜¸ì¬', 'ê¸ì •',
                'ìƒí–¥', 'ê°•ì„¸', 'ë§¤ìˆ˜', 'ì¶”ì²œ', 'ê¸°ëŒ€', 'í¬ë§', 'ì„±ê³µ', 'ëŒíŒŒ', 'ìµœê³ ', 'ìµœëŒ€',
                'rise', 'gain', 'surge', 'jump', 'increase', 'growth', 'positive', 'bullish',
                'upgrade', 'recommend', 'expect', 'hope', 'success', 'breakthrough', 'record'
            ],
            'negative': [
                'í•˜ë½', 'ê¸‰ë½', 'í­ë½', 'ìœ„í—˜', 'ìš°ë ¤', 'ë¶€ì •', 'ì•…í™”', 'ê°ì†Œ', 'ì¶•ì†Œ', 'ì†ì‹¤',
                'í•˜í–¥', 'ì•½ì„¸', 'ë§¤ë„', 'ê²½ê³ ', 'ì‹¤íŒ¨', 'ìœ„ê¸°', 'ì¶©ê²©', 'ìµœì €', 'ìµœì†Œ', 'íì‡„',
                'fall', 'drop', 'crash', 'risk', 'concern', 'negative', 'bearish', 'downgrade',
                'sell', 'warning', 'failure', 'crisis', 'shock', 'close', 'bankruptcy'
            ],
            'neutral': [
                'ë°œí‘œ', 'ê³µê°œ', 'ì§„í–‰', 'ê³„íš', 'ê²€í† ', 'ë…¼ì˜', 'í˜‘ì˜', 'í•©ì˜', 'ì²´ê²°', 'ì™„ë£Œ',
                'announce', 'release', 'plan', 'review', 'discuss', 'agree', 'complete'
            ]
        }
        
        # ì£¼ì œë³„ í‚¤ì›Œë“œ ë¶„ë¥˜
        self.topic_keywords = {
            'ê¸°ìˆ ': ['AI', 'ì¸ê³µì§€ëŠ¥', 'ë°˜ë„ì²´', 'ì¹©', 'ë©”ëª¨ë¦¬', 'ìŠ¤ë§ˆíŠ¸í°', '5G', '6G', 'ë¸”ë¡ì²´ì¸', 'í´ë¼ìš°ë“œ'],
            'ê¸ˆìœµ': ['ì£¼ì‹', 'íˆ¬ì', 'í€ë“œ', 'ì€í–‰', 'ë³´í—˜', 'ì¦ê¶Œ', 'ê¸ˆë¦¬', 'í™˜ìœ¨', 'ë¶€ë™ì‚°', 'ëŒ€ì¶œ'],
            'ê²½ì œ': ['GDP', 'ì¸í”Œë ˆì´ì…˜', 'ë¬¼ê°€', 'ìˆ˜ì¶œ', 'ìˆ˜ì…', 'ë¬´ì—­', 'ê³ ìš©', 'ì‹¤ì—…ë¥ ', 'ì†Œë¹„', 'ìƒì‚°'],
            'ì •ì¹˜': ['ì •ë¶€', 'êµ­íšŒ', 'ë²•ì•ˆ', 'ì •ì±…', 'ì„ ê±°', 'ì™¸êµ', 'êµ­ì œ', 'í˜‘ì •', 'ì¡°ì•½', 'íšŒë‹´'],
            'ì‚¬íšŒ': ['êµìœ¡', 'ì˜ë£Œ', 'í™˜ê²½', 'êµí†µ', 'ë³µì§€', 'ì•ˆì „', 'ë²”ì£„', 'ì‚¬ê³ ', 'ì¬ë‚œ', 'ê¸°ë¶€']
        }

    def analyze_news_sentiment(self, title, source=None):
        """ë‰´ìŠ¤ ì œëª© ê¸°ë°˜ ê°ì • ë¶„ì„"""
        title_lower = title.lower()
        
        positive_score = 0
        negative_score = 0
        neutral_score = 0
        
        # ê°ì • í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
        for keyword in self.sentiment_keywords['positive']:
            if keyword.lower() in title_lower:
                positive_score += 1
        
        for keyword in self.sentiment_keywords['negative']:
            if keyword.lower() in title_lower:
                negative_score += 1
        
        for keyword in self.sentiment_keywords['neutral']:
            if keyword.lower() in title_lower:
                neutral_score += 1
        
        # ê°ì • íŒì •
        if positive_score > negative_score and positive_score > neutral_score:
            return 'positive', positive_score
        elif negative_score > positive_score and negative_score > neutral_score:
            return 'negative', negative_score
        elif neutral_score > 0:
            return 'neutral', neutral_score
        else:
            return 'unknown', 0

    def classify_news_topic(self, title):
        """ë‰´ìŠ¤ ì œëª© ê¸°ë°˜ ì£¼ì œ ë¶„ë¥˜"""
        title_lower = title.lower()
        topic_scores = {}
        
        for topic, keywords in self.topic_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword.lower() in title_lower:
                    score += 1
            if score > 0:
                topic_scores[topic] = score
        
        if topic_scores:
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì£¼ì œ ë°˜í™˜
            return max(topic_scores.items(), key=lambda x: x[1])[0]
        else:
            return 'ê¸°íƒ€'

    def extract_key_entities(self, title):
        """ë‰´ìŠ¤ ì œëª©ì—ì„œ ì£¼ìš” ì—”í‹°í‹° ì¶”ì¶œ"""
        entities = {
            'companies': [],
            'people': [],
            'locations': [],
            'numbers': []
        }
        
        # íšŒì‚¬ëª… íŒ¨í„´ (ëŒ€ë¬¸ì + ì£¼ì‹íšŒì‚¬, (ì£¼), Corp, Inc ë“±)
        company_patterns = [
            r'[A-Zê°€-í£]+(?:ì£¼ì‹íšŒì‚¬|ãˆœ|ãˆ|Corp|Inc|Ltd|LLC)',
            r'[A-Zê°€-í£]+(?:ê·¸ë£¹|ê·¸ë£¹ì¦ˆ|Group)',
            r'[A-Zê°€-í£]+(?:ì „ì|ì „ê¸°|í™”í•™|ê±´ì„¤|ê¸ˆìœµ|ì€í–‰|ì¦ê¶Œ|ë³´í—˜)'
        ]
        
        for pattern in company_patterns:
            matches = re.findall(pattern, title)
            entities['companies'].extend(matches)
        
        # ìˆ«ì íŒ¨í„´
        number_patterns = [
            r'\d+(?:\.\d+)?(?:%|ì›|ë‹¬ëŸ¬|ì–µ|ë§Œ|ì²œ)',
            r'\d+(?:\.\d+)?(?:ì¡°|ì–µ|ë§Œ|ì²œ)ì›',
            r'\d+(?:\.\d+)?(?:%|percent)'
        ]
        
        for pattern in number_patterns:
            matches = re.findall(pattern, title)
            entities['numbers'].extend(matches)
        
        return entities

    def get_news_statistics(self, keyword, days=7):
        """í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ í†µê³„ ë¶„ì„"""
        try:
            table_name = f'google_news_{keyword.lower()}'
            
            # ìµœê·¼ Nì¼ê°„ ë‰´ìŠ¤ ì¡°íšŒ
            query = f"""
            SELECT * FROM {table_name} 
            WHERE published >= datetime('now', '-{days} days')
            ORDER BY published DESC
            """
            
            cursor = self.db.cursor()
            cursor.execute(query)
            news_list = cursor.fetchall()
            
            if not news_list:
                return None
            
            # ê¸°ë³¸ í†µê³„
            stats = {
                'total_news': len(news_list),
                'date_range': f'ìµœê·¼ {days}ì¼',
                'sources': Counter(),
                'sentiments': Counter(),
                'topics': Counter(),
                'daily_counts': Counter(),
                'entities': {
                    'companies': Counter(),
                    'numbers': Counter()
                }
            }
            
            # ê° ë‰´ìŠ¤ ë¶„ì„
            for news in news_list:
                title = news['title']
                source = news['source']
                published = news['published']
                
                # ì¶œì²˜ë³„ ì¹´ìš´íŠ¸
                stats['sources'][source] += 1
                
                # ê°ì • ë¶„ì„
                sentiment, score = self.analyze_news_sentiment(title, source)
                stats['sentiments'][sentiment] += 1
                
                # ì£¼ì œ ë¶„ë¥˜
                topic = self.classify_news_topic(title)
                stats['topics'][topic] += 1
                
                # ì¼ë³„ ì¹´ìš´íŠ¸
                try:
                    date = datetime.strptime(published, '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d')
                    stats['daily_counts'][date] += 1
                except:
                    pass
                
                # ì—”í‹°í‹° ì¶”ì¶œ
                entities = self.extract_key_entities(title)
                stats['entities']['companies'].update(entities['companies'])
                stats['entities']['numbers'].update(entities['numbers'])
            
            return stats
            
        except Exception as e:
            print(f"í†µê³„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None

    def generate_news_report(self, keyword, days=7):
        """ë‰´ìŠ¤ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        stats = self.get_news_statistics(keyword, days)
        
        if not stats:
            return f"'{keyword}' í‚¤ì›Œë“œì— ëŒ€í•œ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        report = f"""
=== {keyword} ë‰´ìŠ¤ ë¶„ì„ ë¦¬í¬íŠ¸ (ìµœê·¼ {days}ì¼) ===

ğŸ“Š ê¸°ë³¸ í†µê³„
â€¢ ì´ ë‰´ìŠ¤ ìˆ˜: {stats['total_news']}ê°œ
â€¢ ë¶„ì„ ê¸°ê°„: {stats['date_range']}

ğŸ“ˆ ì¼ë³„ ë‰´ìŠ¤ ë°œìƒëŸ‰
"""
        
        # ì¼ë³„ í†µê³„ (ìµœê·¼ 5ì¼)
        for date, count in sorted(stats['daily_counts'].items(), reverse=True)[:5]:
            report += f"â€¢ {date}: {count}ê°œ\n"
        
        report += f"""
ğŸ­ ê°ì • ë¶„ì„
"""
        total = stats['total_news']
        for sentiment, count in stats['sentiments'].most_common():
            percentage = (count / total) * 100
            sentiment_kr = {'positive': 'ê¸ì •', 'negative': 'ë¶€ì •', 'neutral': 'ì¤‘ë¦½', 'unknown': 'ë¯¸ë¶„ë¥˜'}.get(sentiment, sentiment)
            report += f"â€¢ {sentiment_kr}: {count}ê°œ ({percentage:.1f}%)\n"
        
        report += f"""
ğŸ“° ì£¼ìš” ì¶œì²˜
"""
        for source, count in stats['sources'].most_common(5):
            percentage = (count / total) * 100
            report += f"â€¢ {source}: {count}ê°œ ({percentage:.1f}%)\n"
        
        report += f"""
ğŸ·ï¸ ì£¼ì œë³„ ë¶„ë¥˜
"""
        for topic, count in stats['topics'].most_common():
            percentage = (count / total) * 100
            report += f"â€¢ {topic}: {count}ê°œ ({percentage:.1f}%)\n"
        
        report += f"""
ğŸ¢ ì£¼ìš” ì–¸ê¸‰ ê¸°ì—…
"""
        for company, count in stats['entities']['companies'].most_common(5):
            report += f"â€¢ {company}: {count}íšŒ\n"
        
        report += f"""
ğŸ“Š ì£¼ìš” ìˆ˜ì¹˜
"""
        for number, count in stats['entities']['numbers'].most_common(5):
            report += f"â€¢ {number}: {count}íšŒ\n"
        
        return report

    def get_trending_keywords(self, keyword, days=7):
        """í‚¤ì›Œë“œì™€ í•¨ê»˜ ì–¸ê¸‰ë˜ëŠ” íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            table_name = f'google_news_{keyword.lower()}'
            
            query = f"""
            SELECT title FROM {table_name} 
            WHERE published >= datetime('now', '-{days} days')
            """
            
            cursor = self.db.cursor()
            cursor.execute(query)
            titles = [row['title'] for row in cursor.fetchall()]
            
            # ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            all_words = []
            for title in titles:
                # íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  ë‹¨ì–´ ë¶„ë¦¬
                words = re.findall(r'[ê°€-í£A-Za-z0-9]+', title)
                all_words.extend(words)
            
            # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ (ê¸°ë³¸ í‚¤ì›Œë“œ ì œì™¸)
            exclude_words = {keyword.lower(), 'ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ë³´ë„', 'ë°œí‘œ', 'ê³µê°œ', 'ì§„í–‰'}
            word_counts = Counter(word.lower() for word in all_words if word.lower() not in exclude_words)
            
            return word_counts.most_common(10)
            
        except Exception as e:
            print(f"íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    analyzer = MetadataBasedAnalyzer()
    
    # ì‚¼ì„±ì „ì ë‰´ìŠ¤ ë¶„ì„
    print(analyzer.generate_news_report('ì‚¼ì„±ì „ì', 7))
    
    # íŠ¸ë Œë”© í‚¤ì›Œë“œ í™•ì¸
    trending = analyzer.get_trending_keywords('ì‚¼ì„±ì „ì', 7)
    print("\n=== íŠ¸ë Œë”© í‚¤ì›Œë“œ ===")
    for word, count in trending:
        print(f"â€¢ {word}: {count}íšŒ") 